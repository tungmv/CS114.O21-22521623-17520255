{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "2024-07-04 12:22:09.048128: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-04 12:22:09.577170: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array # type: ignore\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV2 # type: ignore\n",
    "from tensorflow.keras import layers, models # type: ignore\n",
    "from tensorflow.keras.models import Model, Sequential # type: ignore\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D # type: ignore\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input # type: ignore\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Define constants\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 5  # Adjust this based on your actual number of classes\n",
    "dataset_path = './data'\n",
    "\n",
    "# Define the class names\n",
    "class_names = {\n",
    "    'Others': 0,\n",
    "    'Honda': 1,\n",
    "    'Suzuki': 2,\n",
    "    'Yamaha': 3,\n",
    "    'VinFast': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to hold image data and labels\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Load images and labels\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(dataset_path, class_name)\n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        if img_path.split('.')[-1].lower() in ['png', 'jpg', 'jpeg']:\n",
    "            X.append(img_path[len(dataset_path)+1:])\n",
    "            y.append(class_names[class_name])\n",
    "\n",
    "# Define KFold cross-validator with 5 splits, shuffling data, and fixed random state\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1337)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Tỉ lệ dữ liệu được ghi vào file\n",
    "sampling_ratio = 0.1\n",
    "\n",
    "# Loop through each fold and perform split\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    # Prepare training and testing data for CSV\n",
    "    train_data = [(X[idx], str(y[idx])) for idx in train_index]\n",
    "    test_data = [(X[idx], str(y[idx])) for idx in test_index]\n",
    "    \n",
    "    # Giảm dữ liệu ghi vào file bằng cách lấy mẫu ngẫu nhiên\n",
    "    reduced_train_data = random.sample(train_data, int(len(train_data) * sampling_ratio))\n",
    "    reduced_test_data = random.sample(test_data, int(len(test_data) * sampling_ratio))\n",
    "    \n",
    "    # Write reduced training data to CSV\n",
    "    with open(f'splits/MotocycleDataset-Splits-{i+1}-Train.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['filename', 'label'])\n",
    "        writer.writerows(reduced_train_data)\n",
    "    \n",
    "    # Write reduced testing data to CSV\n",
    "    with open(f'splits/MotocycleDataset-Splits-{i+1}-Test.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['filename', 'label'])\n",
    "        writer.writerows(reduced_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each fold and perform split\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    # Prepare training and testing data for CSV\n",
    "    train_data = [(X[idx], y[idx]) for idx in train_index]\n",
    "    test_data = [(X[idx], y[idx]) for idx in test_index]\n",
    "    \n",
    "    # Write training data to CSV\n",
    "    with open(f'splits/MotocycleDataset-Splits-{i+1}-Train.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['filename', 'label'])\n",
    "        writer.writerows(train_data)\n",
    "    \n",
    "    # Write testing data to CSV\n",
    "    with open(f'splits/MotocycleDataset-Splits-{i+1}-Test.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['filename', 'label'])\n",
    "        writer.writerows(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datagen(train_csv, test_csv, img_dir):\n",
    "    train_data = pd.read_csv(train_csv)\n",
    "    test_data = pd.read_csv(test_csv)\n",
    "    \n",
    "    # Data augmentation for training data\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Only rescaling for test data\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        train_data,\n",
    "        directory=img_dir,\n",
    "        x_col='filename',\n",
    "        y_col='label',\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    validation_generator = test_datagen.flow_from_dataframe(\n",
    "        test_data,\n",
    "        directory=img_dir,\n",
    "        x_col='filename',\n",
    "        y_col='label',\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_csv, test_csv, img_dir):\n",
    "    train_generator, validation_generator = create_datagen(train_csv, test_csv, img_dir)\n",
    "    \n",
    "    model = build_model()\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=30,  # Adjust epochs as needed\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator)\n",
    "    )\n",
    "\n",
    "    # Visualize training process\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluate the model\n",
    "    Y_pred = model.predict(validation_generator)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "    print('Classification Report')\n",
    "    target_names = list(class_names.keys())\n",
    "    print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data\n"
     ]
    }
   ],
   "source": [
    "print(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating on splits/MotocycleDataset-Splits-1-Train.csv and splits/MotocycleDataset-Splits-1-Test.csv\n",
      "Found 27917 validated image filenames belonging to 5 classes.\n",
      "Found 6980 validated image filenames belonging to 5 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "/home/tony/.local/lib/python3.10/site-packages/PIL/Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 75/873\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32:09\u001b[0m 2s/step - accuracy: 0.2338 - loss: 4.2018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 21:07:43.021387: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7dae24f7f150>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 260, in _get_iterator\n",
      "    for i, batch in enumerate(gen_fn()):\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 253, in generator_fn\n",
      "    yield self.py_dataset[i]\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py\", line 68, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py\", line 313, in _get_batches_of_transformed_samples\n",
      "    img = image_utils.load_img(\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/utils/image_utils.py\", line 236, in load_img\n",
      "    img = pil_image.open(io.BytesIO(f.read()))\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/PIL/Image.py\", line 3339, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "\n",
      "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7dae24f7f150>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 76/873\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32:06\u001b[0m 2s/step - accuracy: 0.2341 - loss: 4.1797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 21:07:44.815193: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: UNKNOWN: UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7dae24f7f150>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 260, in _get_iterator\n",
      "    for i, batch in enumerate(gen_fn()):\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 253, in generator_fn\n",
      "    yield self.py_dataset[i]\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py\", line 68, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py\", line 313, in _get_batches_of_transformed_samples\n",
      "    img = image_utils.load_img(\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/utils/image_utils.py\", line 236, in load_img\n",
      "    img = pil_image.open(io.BytesIO(f.read()))\n",
      "\n",
      "  File \"/home/tony/.local/lib/python3.10/site-packages/PIL/Image.py\", line 3339, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "\n",
      "PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7dae24f7f150>\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nUnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7dae24f7f150>\nTraceback (most recent call last):\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 260, in _get_iterator\n    for i, batch in enumerate(gen_fn()):\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 253, in generator_fn\n    yield self.py_dataset[i]\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py\", line 68, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py\", line 313, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/utils/image_utils.py\", line 236, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/PIL/Image.py\", line 3339, in open\n    raise UnidentifiedImageError(msg)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7dae24f7f150>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_2095]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_csv, test_csv \u001b[38;5;129;01min\u001b[39;00m splits:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining and evaluating on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_csv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_csv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(train_csv, test_csv, img_dir)\u001b[0m\n\u001b[1;32m      2\u001b[0m train_generator, validation_generator \u001b[38;5;241m=\u001b[39m create_datagen(train_csv, test_csv, img_dir)\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model()\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust epochs as needed\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Visualize training process\u001b[39;00m\n\u001b[1;32m     15\u001b[0m acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nUnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7dae24f7f150>\nTraceback (most recent call last):\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 260, in _get_iterator\n    for i, batch in enumerate(gen_fn()):\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 253, in generator_fn\n    yield self.py_dataset[i]\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py\", line 68, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py\", line 313, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/keras/src/utils/image_utils.py\", line 236, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"/home/tony/.local/lib/python3.10/site-packages/PIL/Image.py\", line 3339, in open\n    raise UnidentifiedImageError(msg)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7dae24f7f150>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_2095]"
     ]
    }
   ],
   "source": [
    "splits = [\n",
    "    (\"splits/MotocycleDataset-Splits-1-Train.csv\", \"splits/MotocycleDataset-Splits-1-Test.csv\"),\n",
    "    (\"splits/MotocycleDataset-Splits-2-Train.csv\", \"splits/MotocycleDataset-Splits-2-Test.csv\"),\n",
    "    (\"splits/MotocycleDataset-Splits-3-Train.csv\", \"splits/MotocycleDataset-Splits-3-Test.csv\"),\n",
    "    (\"splits/MotocycleDataset-Splits-4-Train.csv\", \"splits/MotocycleDataset-Splits-4-Test.csv\"),\n",
    "    (\"splits/MotocycleDataset-Splits-5-Train.csv\", \"splits/MotocycleDataset-Splits-5-Test.csv\"),\n",
    "]\n",
    "\n",
    "for train_csv, test_csv in splits:\n",
    "    print(f\"Training and evaluating on {train_csv} and {test_csv}\")\n",
    "    train_and_evaluate(train_csv, test_csv, dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the problem, I would create a new cell in the Jupyter Notebook at index 6 and execute the code block provided, which iterates through the splits and calls the `train_and_evaluate()` function for each split. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
